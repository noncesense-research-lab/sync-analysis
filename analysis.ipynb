{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d87ade",
   "metadata": {},
   "source": [
    "# Sync time analysis\n",
    "\n",
    "Mitchell Krawiec-Thayer (Isthmus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01eae00",
   "metadata": {},
   "source": [
    "A few years ago, I spun up Monero nodes on different instances with varying resource constraints, to see how it impacted sync time. This was mostly a curiosity-driven experiment, but knowing the degree to which CPU/memory constraints impact block processing speed actually has useful implications for analyzing scalability for data-driven protocol design. \n",
    "\n",
    "A more 'controlled' experiment would vary the CPU and RAM separately to isolate their impact, but I was paying for this out of pocket and couldn't afford the server time to execute a search grid or anything like that. Just wanted to see how much of a difference there was between sync time for a flimsy node and a beefy node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba942bc0",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da484b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import isthmuslib  # v0.0.56 << the interface is still fluid, pin the version if you're having issues\n",
    "from typing import Dict, List, Tuple\n",
    "import pathlib\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96826f",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea9513",
   "metadata": {},
   "source": [
    "### Specify log file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f332112",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory: pathlib.Path = pathlib.Path.cwd() / 'data' / 'version_controlled'\n",
    "log_filenames: List[str] = ['sync_16_GB_6_CPU.txt',  'sync_192_GB_32_CPU.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8262e77",
   "metadata": {},
   "source": [
    "Here is what the raw log files from a syncing Monero node look like:\n",
    "\n",
    "```\n",
    "bitmonero.log-2018-08-30-22-05-06:2018-08-30 22:05:05.981\t[P2P8]\tINFO \tglobal\tsrc/cryptonote_protocol/cryptonote_protocol_handler.inl:1171\t\u001b[1;33m[94.61.229.18:18080 OUT]  Synced 26936/1650571 (0.453544 sec, 220.485774 blocks/sec), 19.487507 MB queued: [27035:oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo.oooo...]\u001b[0m\n",
    "bitmonero.log-2018-08-30-22-05-14:2018-08-30 22:05:06.343\t[P2P8]\tINFO \tglobal\tsrc/cryptonote_protocol/cryptonote_protocol_handler.inl:1171\t\u001b[1;33m[94.61.229.18:18080 OUT]  Synced 27036/1650571 (0.361146 sec, 276.896324 blocks/sec), 19.479160 MB queued: [27135:ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo.ooooo...]\u001b[0m\n",
    "bitmonero.log-2018-08-30-22-05-14:2018-08-30 22:05:06.756\t[P2P8]\tINFO \tglobal\tsrc/cryptonote_protocol/cryptonote_protocol_handler.inl:1171\t\u001b[1;33m[94.61.229.18:18080 OUT]  Synced 27136/1650571 (0.409780 sec, 244.033384 blocks/sec), 19.729010 MB queued: [27235:oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo.ooooo.o..]\u001b[0m\n",
    "bitmonero.log-2018-08-30-22-05-14:2018-08-30 22:05:07.139\t[P2P8]\tINFO \tglobal\tsrc/cryptonote_protocol/cryptonote_protocol_handler.inl:1171\t\u001b[1;33m[94.61.229.18:18080 OUT]  Synced 27236/1650571 (0.381557 sec, 262.084040 blocks/sec), 19.738058 MB queued: [27335:ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo.ooooooo...]\u001b[0m\n",
    "bitmonero.log-2018-08-30-22-05-14:2018-08-30 22:05:07.550\t[P2P8]\tINFO \tglobal\tsrc/cryptonote_protocol/cryptonote_protocol_handler.inl:1171\t\u001b[1;33m[94.61.229.18:18080 OUT]  Synced 27336/1650571 (0.409511 sec, 244.193685 blocks/sec), 19.800440 MB queued: \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891512f",
   "metadata": {},
   "source": [
    "### Custom log parsing rules (if necessary)\n",
    "\n",
    "Isthmuslib contains no-parameter autoparsing tools that you can use for very clean one-line extractions if you are able to have the logs generated with the standard tokens: `[@@@]` between records, with `[<<`varname`=`value`>>]`\n",
    "\n",
    "In this case we are taking **raw logs from software that I didn't write**, so we provide custom parsing tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify what substring indicates that a new record is starting (lines of logs per row can be many-to-one)\n",
    "record_delimiter: str = 'monero.' \n",
    "    \n",
    "# Specify names and tokens for parsing each record. Dictionary with items 'varname': ('left_token', 'right_token')\n",
    "tokens_dictionary: Dict[str, Tuple[str,str]] = {\n",
    "    'date_time_stamp': ('log-','\\t[P'),\n",
    "    'height': ('Synced ', '/'),\n",
    "    'time_to_load': ('(', ' sec'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2fb2a3",
   "metadata": {},
   "source": [
    "Additionally, we'll define a small feature engineering helper function that takes the log and performs minor tweaks like extracting unique clean runs, parsing the clunky datetime string into a unix timestamp, and calculating the relative timestamps. We can accomplish this pretty easily by interacting directly with the pandas methods available to the dataframe in the `data` attribute.\n",
    "\n",
    "**(Note, the next cell is a custom parser for this particular log format, not useful in general)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inplace_feature_engineering(log: isthmuslib.VectorMultiset) -> None:\n",
    "    \n",
    "    # Only want syncing data\n",
    "    log.data.dropna(inplace=True)  \n",
    "    \n",
    "    \n",
    "    # Just look at the first run if multiple syncs per node\n",
    "    log.data['height'] = log.data['height'].astype(int)\n",
    "    log.data = log.data.groupby(by='height').first()  \n",
    "    log.data.reset_index(inplace=True, drop=False)\n",
    "    log.data.sort_values(by='height',ascending=True, inplace=True, ignore_index=True)\n",
    "\n",
    "    \n",
    "    # Convert datetime strings to timestamps and compute the relative timestamps\n",
    "    custom_parse = lambda b: isthmuslib.machine_time(f\"{b[0]}:{b[1]}:{b[2]}\".replace('\\t',''))\n",
    "    log.data['timestamp'] = [custom_parse(x.split(':')[1:]) for x in log.data['date_time_stamp']]\n",
    "    min_timestamp: float = min(log.data['timestamp'])\n",
    "    log.data['relative_timestamp'] = [x - min_timestamp for x in log.data['timestamp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2301ce84",
   "metadata": {},
   "source": [
    "## Use `isthmuslib` methods to extract and plot from in the logs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e1340",
   "metadata": {},
   "source": [
    "Here's the main part, where we loop over the log files. The two main steps are:\n",
    "+ `log = isthmuslib.extract_file_to_vector(...)` to automatically extract the numeric data out of the raw text logs\n",
    "+ `log.plot('height', 'relative_timestamp')` allows us to easily make a plot to peek at any two variables from the log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs: List[isthmuslib.VectorMultiset] = []\n",
    "disable_progress_bar: bool = True  # Pass None to turn on progress bars\n",
    "for i, filename in enumerate(log_filenames):\n",
    "        \n",
    "    # Identify the full file path\n",
    "    full_path: pathlib.Path = log_directory / filename\n",
    "    print(f\"... Extracting and processing data from file #{i+1} of {len(log_filenames)}\")\n",
    "\n",
    "    # Read in the log\n",
    "    log: isthmuslib.VectorMultiset = isthmuslib.extract_file_to_vector(full_path, \n",
    "                                                              record_delimiter=record_delimiter, \n",
    "                                                              tokens_dictionary=tokens_dictionary,\n",
    "                                                                disable_progress_bar=disable_progress_bar)\n",
    "\n",
    "    # Apply feature engineering\n",
    "    inplace_feature_engineering(log)\n",
    "    \n",
    "    # Plot the run\n",
    "    log.scatter('height', 'relative_timestamp', title=f\"Data extracted from {filename}\", figsize=(7,3))\n",
    "    \n",
    "    # Cache the data\n",
    "    log.name_root = filename.replace('_',' ').replace('.txt', '').replace('sync ','')\n",
    "    logs.append(deepcopy(log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46459305",
   "metadata": {},
   "source": [
    "## Summary plot (combine data onto same axes with labels and fork heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fd988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the base scatterplot\n",
    "isthmuslib.scatter([[log.data.height, log.data.relative_timestamp / (60 * 60)] for log in logs],\n",
    "               xlabel='height', ylabel='hours into sync', title='Monero node sync times on different devices',\n",
    "                grid=False)\n",
    "\n",
    "# Add fork heights, since somebody will ask about this\n",
    "fork_heights: List[int] = [1009827,1141317,1220516,1288616,1400000,1546000,1685555,1686275]\n",
    "[isthmuslib.plt.axvline(y, color='gray', linewidth=1, linestyle=':') for y in fork_heights];\n",
    "\n",
    "\n",
    "# Add a legend (this is accessing `matplotlib.pyplot` as `plt`)\n",
    "isthmuslib.plt.legend([log.name_root for log in logs] + ['hard fork height'], \n",
    "                      fontsize=isthmuslib.Style().legend_fontsize);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
